{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Developing the project especified in the proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Layer 1: input layer - Dimensions: D (number of sensors or channels) X 400 (number of samples)\n",
    "    - for dataset 1: D=10; for dataset 2 and 3: D=12\n",
    "- Layer 2: Convolutional layer 64\n",
    "- Layer 3: Convolutional layer 64\n",
    "- Layer 4: Convolutional layer 64\n",
    "- Layer 5: Convolutional layer 64\n",
    "- Droupout\n",
    "- Layer 6: Dense layer LSTM 128\n",
    "- Dropout\n",
    "- Layer 7: Dense layer LSTM 64\n",
    "- Layer 8: Softmax layer 50 classes\n",
    "- RMSProp update rule\n",
    "- mini batch gradient descent - size=100, learning rate=0.001, decay factor=0.9\n",
    "- dropout: p=0.5\n",
    "- Test set: 1/4\n",
    "- Training set: 3/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# All three datasets already downloaded to ./datasets/db1, ./datasets/db2 and ./datasets/db3, respectively\n",
    "import nina_helper as nh\n",
    "import numpy as np\n",
    "\n",
    "DB1_PATH = \"./datasets/db1\"\n",
    "DB2_PATH = \"./datasets/db2\"\n",
    "DB3_PATH = \"./datasets/db3\"\n",
    "\n",
    "# Decide window length (200ms window, 100ms increment)\n",
    "window_len = 20\n",
    "window_step = 1\n",
    "\n",
    "# Choose subject and get info\n",
    "subject = 1\n",
    "info_dict = nh.db1_info()  # Get info\n",
    "\n",
    "# Get EMG, repetition and movement data, don't cap maximum length of rest\n",
    "data_dict = nh.import_db1(DB1_PATH, subject)\n",
    "\n",
    "# Create a balanced test - training split based on repetition number\n",
    "reps = info_dict['rep_labels']\n",
    "nb_test_reps = 3\n",
    "train_reps, test_reps = nh.gen_split_balanced(reps, nb_test_reps)\n",
    "\n",
    "# Normalise EMG data based on training set\n",
    "emg_data = nh.normalise_emg(data_dict['emg'], data_dict['rep'], train_reps[0, :])\n",
    "\n",
    "# Window data: x_all data is 4D tensor [observation, time_step, channel, 1] for use with Keras\n",
    "# y_all: movement label, length: number of windows\n",
    "# r_all: repetition label, length: number of windows\n",
    "moves = np.array([1, 3, 5, 20])\n",
    "x_all, y_all, r_all = nh.get_windows(reps, window_len, window_step,\n",
    "                                  emg_data, data_dict['move'],\n",
    "                                  data_dict['rep'],\n",
    "                                  which_moves=moves)\n",
    "\n",
    "train_idx = nh.get_idxs(r_all, train_reps[0, :])\n",
    "train_data = x_all[train_idx, :, :, :]\n",
    "one_hot_categorical = nh.to_categorical(y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "14778\n",
      "[ 1  1  1  1  1  1  1  2  2  2  2  2  2  2  3  3  3  3  3  3  3  4  4  4\n",
      "  4  4  4  4  5  5  5  5  5  5  5  5  5  6  6  6  6  6  6  6  7  7  7  7\n",
      "  7  7  7  7  7  8  8  8  8  8  8  8  8  9  9  9  9  9  9  9  9  9 10 10\n",
      " 10 10 10 10 10  1  1  1  1  1  1  1  1  1  1  2  2  2  2  2  2  2  2  3\n",
      "  3  3  3  3  3  3  3  3  3  4  4  4  4  4  4  4  4  5  5  5  5  5  5  5\n",
      "  5  5  5  6  6  6  6  6  6  6  6  6  6  7  7  7  7  8  8  8  8  8  8  8\n",
      "  9  9  9  9  9  9  9  9  9 10 10 10 10 10 10 10  1  1  1  1  1  1  1  1\n",
      "  1  2  2  2  2  2  2  2  2  2  3  3  3  3  3  3  3  4  4  4  4  4  4  4\n",
      "  4  4  5  5  5  5  5  5  5  6  6  6  6  6  6  6  6  6  7  7  7  7  7  7\n",
      "  7  7  8  8  8  8  8  8  8  9  9  9  9  9  9 10 10 10 10 10 10 10 10  1\n",
      "  1  1  1  1  1  2  2  2  2  2  2  3  3  3  3  3  4  4  4  4  5  5  5  5\n",
      "  5  5  5  6  6  6  6  6  6  7  7  7  7  7  7  7  8  8  8  8  8  9  9  9\n",
      "  9  9 10 10 10 10 10 10]\n",
      "20\n",
      "dict_keys(['right_handed_ind', 'nb_reps', 'nb_channels', 'nb_subjects', 'nb_moves', 'rep_labels', 'fs', 'female_ind', 'right_handed', 'heights', 'left_handed', 'female', 'move_labels', 'male_ind', 'left_handed_ind', 'weights', 'male', 'ages'])\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53]\n",
      "[ 1  2  3  4  5  6  7  8  9 10]\n"
     ]
    }
   ],
   "source": [
    "print (one_hot_categorical[0])\n",
    "print (len(y_all))\n",
    "print (r_all[0:-1:50])\n",
    "print (max(y_all))\n",
    "print (info_dict.keys())\n",
    "print (info_dict['move_labels'])\n",
    "print (info_dict['rep_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
